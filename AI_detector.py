import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
import threading
import torch
import numpy as np
from transformers import GPT2LMHeadModel, GPT2TokenizerFast

class PerplexityApp:
    def __init__(self, root):
        self.root = root
        self.root.title("GPT-2 æ–‡ç« å›°æƒ‘åº¦åˆ†æ")
        self.root.geometry("800x650") # è¨­å®šè¦–çª—å¤§å°

        # è¼‰å…¥æ¨¡å‹å’Œåˆ†è©å™¨ (åœ¨å–®ç¨çš„åŸ·è¡Œç·’ä¸­è¼‰å…¥ï¼Œé¿å… GUI å‡çµ)
        self.model = None
        self.tokenizer = None
        self.model_name = "gpt2" # å¯ä»¥æ›æˆ "gpt2-medium" æˆ– "gpt2-large"

        self._create_widgets()
        self._load_model_async()

    def _create_widgets(self):
        # è¨­å®šæ•´é«”ä½ˆå±€çš„ padding
        main_frame = ttk.Frame(self.root, padding="15 15 15 15")
        main_frame.pack(fill="both", expand=True)
        main_frame.columnconfigure(0, weight=1)

        # 1. è¼¸å…¥æ–‡æœ¬å€åŸŸ
        ttk.Label(main_frame, text="è«‹è¼¸å…¥æ‚¨çš„è‹±æ–‡æ–‡ç« ï¼š", font=('Arial', 12, 'bold')).grid(row=0, column=0, sticky="w", pady=(0, 5))
        
        self.input_text = scrolledtext.ScrolledText(main_frame, wrap=tk.WORD, width=80, height=15, font=('Arial', 10))
        self.input_text.grid(row=1, column=0, sticky="nsew", pady=(0, 10))
        # ç¶å®š ctrl+a å…¨é¸
        self.input_text.bind("<Control-a>", self.select_all_text)
        self.input_text.bind("<Command-a>", self.select_all_text) # For macOS

        # 2. æ¨¡å‹åŠ è¼‰ç‹€æ…‹
        self.status_var = tk.StringVar()
        self.status_var.set("æ­£åœ¨è¼‰å…¥æ¨¡å‹ï¼Œè«‹ç¨å€™...")
        self.status_label = ttk.Label(main_frame, textvariable=self.status_var, font=('Arial', 10, 'italic'), foreground='blue')
        self.status_label.grid(row=2, column=0, sticky="w", pady=(0, 10))

        # 3. è¨ˆç®—æŒ‰éˆ•
        self.calculate_button = ttk.Button(main_frame, text="è¨ˆç®—å›°æƒ‘åº¦", command=self._start_calculation, state=tk.DISABLED)
        self.calculate_button.grid(row=3, column=0, sticky="ew", pady=(0, 20))

        # 4. çµæœé¡¯ç¤ºå€åŸŸ
        ttk.Label(main_frame, text="=== åˆ†æçµæœ ===", font=('Arial', 12, 'bold')).grid(row=4, column=0, sticky="w", pady=(10, 5))

        # å›°æƒ‘åº¦
        self.ppl_var = tk.StringVar()
        ttk.Label(main_frame, text="æ•´é«”å¹³å‡å›°æƒ‘åº¦ï¼ˆPPLï¼‰ï¼š", font=('Arial', 11)).grid(row=5, column=0, sticky="w", padx=(10, 0))
        ttk.Label(main_frame, textvariable=self.ppl_var, font=('Arial', 11, 'bold'), foreground='darkgreen').grid(row=5, column=0, sticky="e", padx=(0, 10))

        # Token æå¤±è®Šç•°é‡
        self.var_loss_var = tk.StringVar()
        ttk.Label(main_frame, text="Tokenæå¤±è®Šç•°é‡ï¼š", font=('Arial', 11)).grid(row=6, column=0, sticky="w", padx=(10, 0))
        ttk.Label(main_frame, textvariable=self.var_loss_var, font=('Arial', 11, 'bold'), foreground='darkgreen').grid(row=6, column=0, sticky="e", padx=(0, 10))

        # åˆ¤æ–·çµæœ
        self.prediction_var = tk.StringVar()
        ttk.Label(main_frame, text="åˆ¤æ–·çµæœï¼š", font=('Arial', 11)).grid(row=7, column=0, sticky="w", pady=(10, 5), padx=(10, 0))
        self.prediction_label = ttk.Label(main_frame, textvariable=self.prediction_var, font=('Arial', 12, 'bold'), foreground='purple')
        self.prediction_label.grid(row=7, column=0, sticky="e", pady=(10, 5), padx=(0, 10))

        # åº•éƒ¨èªªæ˜
        ttk.Label(main_frame, text="æç¤ºï¼šPPL è¶Šä½ï¼Œé€šå¸¸è¡¨ç¤ºæ–‡æœ¬å°æ¨¡å‹è€Œè¨€è¶Šå®¹æ˜“é æ¸¬ã€‚", font=('Arial', 9, 'italic')).grid(row=8, column=0, sticky="w", pady=(10, 0))
        ttk.Label(main_frame, text="æ³¨æ„ï¼šé€™äº›åˆ¤æ–·é–¾å€¼æ˜¯ç¶“é©—æ€§çš„ï¼Œå¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš›æ‡‰ç”¨èª¿æ•´ã€‚", font=('Arial', 9, 'italic')).grid(row=9, column=0, sticky="w", pady=(0, 5))

        # è¨­ç½®è¡Œå’Œåˆ—çš„æ¬Šé‡ï¼Œè®“å…¶éš¨è¦–çª—å¤§å°è®ŠåŒ–
        main_frame.rowconfigure(1, weight=1) # è¼¸å…¥æ–‡æœ¬å€åŸŸå¯ä»¥æ“´å±•

    def select_all_text(self, event=None):
        self.input_text.tag_add("sel", "1.0", "end-1c")
        return "break" # Prevents the default behavior of the event

    def _load_model_async(self):
        """åœ¨å–®ç¨çš„åŸ·è¡Œç·’ä¸­åŠ è¼‰æ¨¡å‹ï¼Œé¿å…é˜»å¡ GUI"""
        self.calculate_button.config(state=tk.DISABLED)
        self.status_var.set(f"æ­£åœ¨è¼‰å…¥ GPT-2 æ¨¡å‹ ({self.model_name})... è«‹ç¨å€™...")
        self.root.update_idletasks() # å¼·åˆ¶æ›´æ–° GUI

        def load_task():
            try:
                self.model = GPT2LMHeadModel.from_pretrained(self.model_name)
                self.tokenizer = GPT2TokenizerFast.from_pretrained(self.model_name)
                self.model.eval()
                self.root.after(0, self._on_model_loaded, True) # å›åˆ°ä¸»åŸ·è¡Œç·’æ›´æ–° GUI
            except Exception as e:
                self.root.after(0, self._on_model_loaded, False, str(e))

        threading.Thread(target=load_task).start()

    def _on_model_loaded(self, success, error_message=None):
        if success:
            self.status_var.set(f"æ¨¡å‹ {self.model_name} è¼‰å…¥å®Œæˆï¼Œå¯ä»¥é–‹å§‹åˆ†æã€‚")
            self.calculate_button.config(state=tk.NORMAL)
        else:
            self.status_var.set(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {error_message}")
            messagebox.showerror("éŒ¯èª¤", f"ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼š{error_message}\nè«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥æˆ–æ¨¡å‹åç¨±ã€‚")
            self.calculate_button.config(state=tk.DISABLED)

    def _start_calculation(self):
        """å•Ÿå‹•è¨ˆç®—ï¼Œä¸¦åœ¨å–®ç¨çš„åŸ·è¡Œç·’ä¸­åŸ·è¡Œ"""
        text = self.input_text.get("1.0", "end-1c").strip() # ç²å–æ–‡æœ¬ä¸¦ç§»é™¤æœ«å°¾æ›è¡Œç¬¦

        if not text:
            messagebox.showwarning("è¼¸å…¥éŒ¯èª¤", "è«‹åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥æ–‡ç« å¾Œå†è¨ˆç®—ã€‚")
            return

        if self.model is None or self.tokenizer is None:
            messagebox.showerror("éŒ¯èª¤", "æ¨¡å‹å°šæœªè¼‰å…¥å®Œæˆï¼Œè«‹ç¨å€™ã€‚")
            return

        self.calculate_button.config(state=tk.DISABLED)
        self.status_var.set("æ­£åœ¨è¨ˆç®—ä¸­...è«‹ç¨å€™...")
        self.ppl_var.set("")
        self.var_loss_var.set("")
        self.prediction_var.set("")
        self.root.update_idletasks() # å¼·åˆ¶æ›´æ–° GUI

        def calculation_task():
            try:
                avg_ppl, var_token_losses, prediction_text = self._calculate_perplexity(text)
                self.root.after(0, self._on_calculation_complete, avg_ppl, var_token_losses, prediction_text)
            except Exception as e:
                self.root.after(0, self._on_calculation_error, str(e))

        threading.Thread(target=calculation_task).start()

    def _on_calculation_complete(self, avg_ppl, var_token_losses, prediction_text):
        """è¨ˆç®—å®Œæˆå¾Œæ›´æ–° GUI"""
        self.ppl_var.set(f"{avg_ppl:.2f}" if avg_ppl != float('inf') else "N/A (æ–‡æœ¬éçŸ­)")
        self.var_loss_var.set(f"{var_token_losses:.2f}" if var_token_losses != float('inf') else "N/A (æ–‡æœ¬éçŸ­)")
        self.prediction_var.set(prediction_text)
        self.status_var.set("è¨ˆç®—å®Œæˆã€‚")
        self.calculate_button.config(state=tk.NORMAL)

        # æ ¹æ“šé æ¸¬çµæœèª¿æ•´é æ¸¬æ–‡å­—çš„é¡è‰²
        if "æ¥µé«˜å¯èƒ½æ˜¯AIç”Ÿæˆå…§å®¹" in prediction_text:
            self.prediction_label.config(foreground='red')
        elif "å¯èƒ½æ˜¯AIç”Ÿæˆ" in prediction_text:
            self.prediction_label.config(foreground='orange')
        elif "è¼ƒå¯èƒ½æ˜¯äººé¡æ’°å¯«" in prediction_text:
            self.prediction_label.config(foreground='darkblue')
        elif "æ¥µé«˜å¯èƒ½æ˜¯äººé¡æ’°å¯«" in prediction_text:
            self.prediction_label.config(foreground='green')
        else:
            self.prediction_label.config(foreground='purple') # é»˜èªé¡è‰²

    def _on_calculation_error(self, error_message):
        """è¨ˆç®—å‡ºéŒ¯æ™‚æ›´æ–° GUI"""
        self.status_var.set("è¨ˆç®—å¤±æ•—ã€‚")
        messagebox.showerror("éŒ¯èª¤", f"è¨ˆç®—éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{error_message}")
        self.calculate_button.config(state=tk.NORMAL)


    def _calculate_perplexity(self, text):
        """
        æ ¸å¿ƒå›°æƒ‘åº¦è¨ˆç®—é‚è¼¯ï¼Œèˆ‡åŸå§‹ç¨‹å¼ç¢¼ç›¸åŒ
        """
        inputs = self.tokenizer(text, return_tensors="pt")
        input_ids = inputs["input_ids"]

        avg_ppl = float('inf')
        var_token_losses = float('inf')
        prediction_text = "ç„¡æ³•åˆ¤æ–· (æ–‡æœ¬éçŸ­æˆ–éŒ¯èª¤)"

        if input_ids.shape[1] <= 1:
            prediction_text = "âš ï¸ è­¦å‘Šï¼šè¼¸å…¥æ–‡æœ¬éçŸ­ï¼Œç„¡æ³•è¨ˆç®—æœ‰æ•ˆçš„å›°æƒ‘åº¦ã€‚"
        else:
            with torch.no_grad():
                outputs = self.model(input_ids, labels=input_ids)
                overall_loss = outputs.loss.item()
                logits = outputs.logits

                shift_logits = logits[:, :-1, :].contiguous()
                shift_labels = input_ids[:, 1:].contiguous()
                
                loss_fct = torch.nn.CrossEntropyLoss(reduction='none')
                token_losses = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
                token_losses_np = token_losses.detach().cpu().numpy()

                avg_ppl = np.exp(overall_loss)
                var_token_losses = np.var(token_losses_np)

            # ç°¡å–®åˆ¤æ–·ï¼ˆå¯å¾®èª¿é–¾å€¼ï¼‰
            ai_ai_threshold = 30       # å¦‚æœ PPL ä½æ–¼æ­¤å€¼ï¼Œå¯èƒ½å‚¾å‘æ–¼ AI
            ai_mix_threshold = 100       # å¦‚æœ PPL ä½æ–¼æ­¤å€¼ï¼Œå¯èƒ½å‚¾å‘æ–¼ AI
            ai_var_loss_threshold = 13 # å¦‚æœæå¤±è®Šç•°é‡ä½æ–¼æ­¤å€¼ï¼Œå¯èƒ½å‚¾å‘æ–¼ AI

            if avg_ppl < ai_ai_threshold and var_token_losses < ai_var_loss_threshold:
                prediction_text = "ğŸ¤– æ¥µé«˜å¯èƒ½æ˜¯AIç”Ÿæˆå…§å®¹ (PPLæ¥µä½ï¼Œé«˜åº¦å¯é æ¸¬ä¸”å¹³æ»‘)"
            elif avg_ppl < ai_ai_threshold and var_token_losses >= ai_var_loss_threshold:
                prediction_text = "ğŸ¤– å¯èƒ½æ˜¯AIç”Ÿæˆï¼Œä½†åŒ…å«éå…¸å‹æ¨¡å¼ (PPLä½ï¼Œä½†è©èªé æ¸¬é›£åº¦æ³¢å‹•è¼ƒå¤§)"
            elif avg_ppl >= ai_ai_threshold and avg_ppl < ai_mix_threshold and var_token_losses < ai_var_loss_threshold:
                prediction_text = "ğŸ¤” å¯èƒ½æ˜¯AIç”Ÿæˆæˆ–ç¶“éé«˜åº¦æ½¤é£¾çš„å…§å®¹ (PPLä¸­ç­‰ï¼Œä½†çµæ§‹æ¥µç‚ºå¹³ç©©)"
            elif avg_ppl >= ai_ai_threshold and avg_ppl < ai_mix_threshold and var_token_losses >= ai_var_loss_threshold:
                prediction_text = "âœ… è¼ƒå¯èƒ½æ˜¯äººé¡æ’°å¯« (PPLä¸­ç­‰ï¼Œèªæ°£æˆ–è¡¨é”å…·å‚™è‡ªç„¶æ³¢å‹•)"
            else: # avg_ppl >= ai_mix_threshold
                prediction_text = "âœ… æ¥µé«˜å¯èƒ½æ˜¯äººé¡æ’°å¯« (PPLé«˜ï¼Œæ¨¡å‹é æ¸¬å›°é›£ï¼Œç¬¦åˆäººé¡å¯«ä½œç‰¹é»)"
        
        return avg_ppl, var_token_losses, prediction_text

if __name__ == "__main__":
    root = tk.Tk()
    app = PerplexityApp(root)
    root.mainloop()